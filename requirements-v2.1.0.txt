# WebScrape-TUI v2.1.0 - Python Dependencies
#
# This file lists all Python packages required for v2.1.0 (Architecture Refactor)
# Install all dependencies with: pip install -r requirements-v2.1.0.txt
#
# Total Dependencies: 30 production packages (22 existing + 8 new for v2.1.0)
# Last Updated: October 3, 2025 (v2.1.0 development)

# ===== EXISTING DEPENDENCIES (v2.0.0) =====

# Core TUI Framework
textual>=0.40.0

# Web Scraping and HTTP
requests>=2.31.0

# HTML/XML Parsing
beautifulsoup4>=4.12.0
lxml>=4.9.0

# Configuration Management
PyYAML>=6.0.0

# Scheduling and Automation
APScheduler>=3.10.0

# Data Visualization and Analytics
matplotlib>=3.7.0
pandas>=2.0.0

# Enhanced Export Formats
openpyxl>=3.1.0
reportlab>=4.0.0
wordcloud>=1.9.0

# Advanced AI Features
spacy>=3.7.0
sentence-transformers>=2.2.0
scipy>=1.11.0
nltk>=3.8.0
scikit-learn>=1.3.0

# Smart Categorization & Topic Modeling
gensim>=4.3.0,<4.4.0
networkx>=3.0
rouge-score>=0.1.2
fuzzywuzzy>=0.18.0
python-Levenshtein>=0.20.0

# Multi-User Support & Authentication
bcrypt>=4.0.0,<5.0.0

# ===== NEW DEPENDENCIES (v2.1.0) =====

# REST API Framework
# FastAPI for high-performance REST API with automatic OpenAPI documentation
fastapi>=0.104.0

# ASGI Server
# Uvicorn with optional standard extras (websockets, httptools, uvloop)
uvicorn[standard]>=0.24.0

# Data Validation
# Pydantic v2 for request/response validation and serialization
pydantic>=2.5.0

# JWT Authentication
# Python-Jose for JWT token generation and verification
python-jose[cryptography]>=3.3.0

# Async SQLite
# aiosqlite for async database operations
aiosqlite>=0.19.0

# CLI Framework
# Click for command-line interface
click>=8.1.0

# Redis Cache (Optional)
# Redis client for caching (optional, falls back to memory cache)
redis>=5.0.0

# Retry Logic
# Tenacity for robust retry mechanisms with exponential backoff
tenacity>=8.2.0

# Async HTTP Client
# httpx for async HTTP requests (used in API client and testing)
httpx>=0.25.0

# ===== DEVELOPMENT DEPENDENCIES (requirements-dev.txt) =====
# Uncomment or install separately for development:
#
# pytest>=7.4.0                     # Testing framework
# pytest-asyncio>=0.21.0            # Async test support
# pytest-mock>=3.12.0               # Mock fixtures
# pytest-cov>=4.1.0                 # Coverage reporting
# black>=23.0.0                     # Code formatting
# ruff>=0.1.0                       # Fast linter
# mypy>=1.7.0                       # Type checking
# httpx>=0.25.0                     # For API testing

# ===== INSTALLATION INSTRUCTIONS =====

# 1. Create virtual environment:
#    python -m venv venv
#    source venv/bin/activate  # On Windows: venv\Scripts\activate

# 2. Install dependencies:
#    pip install -r requirements-v2.1.0.txt

# 3. Download spaCy model:
#    python -m spacy download en_core_web_sm

# 4. (Optional) Install development dependencies:
#    pip install -r requirements-dev.txt

# 5. Run application:
#    # TUI mode
#    python -m scrapetui
#
#    # API mode
#    python -m scrapetui.api
#
#    # CLI mode
#    python -m scrapetui.cli --help

# ===== SYSTEM REQUIREMENTS =====

# Python Version:
# - Python 3.8 to 3.12 (Python 3.10-3.12 recommended)
# - Python 3.13 NOT supported yet (gensim incompatible)

# Platform Requirements:
# - Terminal with Unicode support
# - Internet connection for web scraping
# - Optional: Redis server for caching (can use memory cache instead)

# ===== OPTIONAL FEATURES =====

# Redis Caching (Recommended for production):
# Set CACHE_TYPE=redis in .env file
# Requires Redis server running on localhost:6379 or configured host

# API Authentication:
# Set API_JWT_SECRET in .env file
# Generate with: python -c "import secrets; print(secrets.token_hex(32))"

# ===== VERSION NOTES =====

# v2.1.0 New Features:
# - Modular architecture (40+ files)
# - Plugin system for scrapers and AI providers
# - REST API with JWT authentication
# - CLI interface for automation
# - Async database operations
# - Caching layer (memory/Redis)
# - Improved performance and scalability

# Breaking Changes:
# - None - full backward compatibility maintained
# - Legacy scrapetui.py entry point still works
# - Automatic database migration from v2.0.0

# Migration from v2.0.0:
# 1. Backup database: cp scraped_data_tui_v1.0.db{,.backup}
# 2. Install new dependencies: pip install -r requirements-v2.1.0.txt
# 3. Run application (automatic migration)
# 4. Test functionality
# 5. Remove backup if successful
